import os
from langchain_openai import ChatOpenAI
from bedrock_agentcore.identity.auth import requires_api_key
from dotenv import load_dotenv


@requires_api_key(provider_name=os.getenv("BEDROCK_AGENTCORE_MODEL_PROVIDER_API_KEY_NAME", ""))
def agentcore_identity_api_key_provider(api_key: str) -> str:
    return api_key


def load_model() -> ChatOpenAI:
    """
    Get authenticated OpenAI model client.
    Uses AgentCore Identity for API key management in deployed environments,
    and falls back to .env file for local development.
    """
    if os.getenv("LOCAL_DEV") == "1":
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
    else:
        api_key = agentcore_identity_api_key_provider()

    return ChatOpenAI(
        model="gpt-5.1",
        api_key=api_key
    )
