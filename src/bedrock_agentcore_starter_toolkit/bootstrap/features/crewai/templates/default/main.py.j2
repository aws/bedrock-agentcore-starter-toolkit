from crewai import Agent, Crew, LLM, Task, Process
from crewai.tools import tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from mcp_client.client import get_streamable_http_mcp_client

MODEL_ID="bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0"

# Initialize the model client
llm = LLM(model=MODEL_ID)

# Define a simple function tool
@tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a+b

# Import AgentCore Gateway as Streamable HTTP MCP Adapter
mcp_adapter = get_streamable_http_mcp_client()

# Integrate with Bedrock AgentCore
app = BedrockAgentCoreApp()

@app.entrypoint
def invoke(payload):
    # assume payload input is structured as { "prompt": "<user input>" }

    with mcp_adapter as tools:
        # Define the Agent, Task and Crew with Tools
        agent = Agent(
            role="Question Answering Assistant",
            goal="Answer the users questions",
            backstory="Always eager to answer any questions",
            llm=llm,
            tools=[add_numbers] + tools
        )

        task = Task(
            agent=agent,
            description="Answer the users question: {prompt}",
            expected_output="An answer to the users question"
        )

        crew = Crew(
            agents=[agent],
            tasks=[task],
            process=Process.sequential
        )

        # Process the user prompt
        prompt = payload.get("prompt", "What is Agentic AI?")

        # Run the agent
        result = crew.kickoff(inputs={"prompt": prompt})

        # Return result
        return result.raw

if __name__ == "__main__":
    app.run()
